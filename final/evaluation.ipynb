{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378e619c",
   "metadata": {
    "id": "378e619c"
   },
   "source": [
    "# Reinforcement Learning 2025 - Policy Evaluation\n",
    "\n",
    "**Authors:** Amit Ezer, Gal Yaacov Noy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef2caef6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef2caef6",
    "outputId": "7101b050-1c8c-4783-df16-e9fce1b71791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minigrid in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: gymnasium in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: pygame>=2.4.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from minigrid) (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from minigrid) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/galnoy/git-projects/MSC-Reinforcement-Learning/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install minigrid gymnasium matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf2fee7",
   "metadata": {
    "id": "3bf2fee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import minigrid\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video, display\n",
    "from shared_utils import device, set_seeds, preprocess, create_env, QNetwork, ActorCritic\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeceb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, model, model_type=\"dqn\", max_steps=200):\n",
    "    \"\"\"Run a single episode using the provided neural network model.\"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    state = preprocess(obs).to(device)\n",
    "    total_reward, step = 0, 0\n",
    "    terminated = truncated = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while not (terminated or truncated) and step < max_steps:\n",
    "            # Select action based on model type\n",
    "            if model_type == \"dqn\":\n",
    "                # For DQN: greedily select action with highest Q-value\n",
    "                q_values = model(state.unsqueeze(0))\n",
    "                action = q_values.argmax(dim=1).item()\n",
    "            elif model_type == \"ppo\":\n",
    "                # For PPO: sample from policy or use greedy action\n",
    "                logits, _ = model(state.unsqueeze(0))\n",
    "                action = torch.argmax(logits, dim=1).item()  # Greedy action for evaluation\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = preprocess(next_obs).to(device)\n",
    "            total_reward += reward\n",
    "            step += 1\n",
    "            obs = next_obs\n",
    "\n",
    "    success = reward > 0 and terminated\n",
    "    return total_reward, step, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "857e4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, model_type, num_actions, input_size=56):\n",
    "    \"\"\"Load a PyTorch model from a .pth file.\"\"\"\n",
    "    if model_type == \"dqn\":\n",
    "        model = QNetwork(num_actions, input_size=input_size).to(device)\n",
    "    elif model_type == \"ppo\":\n",
    "        model = ActorCritic(num_actions, input_size=input_size).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def evaluate_policy(env, model, model_type=\"dqn\", num_episodes=100, max_steps=200):\n",
    "    \"\"\"Evaluate a neural network policy over multiple episodes.\"\"\"\n",
    "    rewards, steps, successes = [], [], []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        total_reward, step, success = run_episode(env, model, model_type, max_steps)\n",
    "        rewards.append(total_reward)\n",
    "        steps.append(step)\n",
    "        successes.append(success)\n",
    "\n",
    "        if episode % 20 == 0:\n",
    "            print(f\"  Episode {episode}: Reward={total_reward:.2f}, Steps={step}, Success={success}\")\n",
    "\n",
    "    return {\n",
    "        \"rewards\": rewards,\n",
    "        \"steps\": steps,\n",
    "        \"successes\": successes,\n",
    "    }\n",
    "\n",
    "def record_final_video(model, model_type, env_size=\"6x6\", model_name=\"dqn\"):\n",
    "    \"\"\"Record a video of a single greedy policy episode.\"\"\"\n",
    "    env_name = f\"MiniGrid-Dynamic-Obstacles-{env_size}-v0\"\n",
    "    filename = f\"{env_size}-{model_name}-final\"\n",
    "    video_dir = \"videos\"\n",
    "\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "    env_wrapped = RecordVideo(\n",
    "        create_env(env_name, render_mode=\"rgb_array\"),\n",
    "        video_folder=video_dir,\n",
    "        name_prefix=filename,\n",
    "        episode_trigger=lambda _: True\n",
    "    )\n",
    "\n",
    "    run_episode(env_wrapped, model, model_type, max_steps=100)\n",
    "    env_wrapped.close()\n",
    "\n",
    "    return os.path.join(video_dir, f\"{filename}-episode-0.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad25ec2e",
   "metadata": {
    "id": "ad25ec2e"
   },
   "outputs": [],
   "source": [
    "def run_evaluation(config_name, env_name, models_dir=\"models\"):\n",
    "    \"\"\"Run evaluation for a configuration and return results with videos.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"EVALUATING: {config_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    env = create_env(env_name)\n",
    "    num_actions = env.action_space.n\n",
    "    \n",
    "    # Get environment size for model directory\n",
    "    env_suffix = env_name.split('-')[-2].replace('v0', '').strip()\n",
    "    model_folder = os.path.join(models_dir, env_suffix)\n",
    "    env_size = \"6x6\" if \"6x6\" in env_name else (\"5x5\" if \"5x5\" in env_name else \"16x16\")\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # Load and evaluate Double DQN\n",
    "    dqn_path = os.path.join(model_folder, \"double_dqn_model.pth\")\n",
    "    if os.path.exists(dqn_path):\n",
    "        print(\"Loading Double DQN model...\")\n",
    "        dqn_model = load_model(dqn_path, \"dqn\", num_actions)\n",
    "        print(\"Evaluating Double DQN...\")\n",
    "        results[\"Double DQN\"] = evaluate_policy(env, dqn_model, \"dqn\")\n",
    "        results[\"Double DQN\"][\"video\"] = record_final_video(dqn_model, \"dqn\", env_size, \"double_dqn\")\n",
    "    else:\n",
    "        print(f\"Double DQN model not found at: {dqn_path}\")\n",
    "\n",
    "    # Load and evaluate PPO\n",
    "    ppo_path = os.path.join(model_folder, \"ppo_model.pth\")\n",
    "    if os.path.exists(ppo_path):\n",
    "        print(\"Loading PPO model...\")\n",
    "        ppo_model = load_model(ppo_path, \"ppo\", num_actions)\n",
    "        print(\"Evaluating PPO...\")\n",
    "        results[\"PPO\"] = evaluate_policy(env, ppo_model, \"ppo\")\n",
    "        results[\"PPO\"][\"video\"] = record_final_video(ppo_model, \"ppo\", env_size, \"ppo\")\n",
    "    else:\n",
    "        print(f\"PPO model not found at: {ppo_path}\")\n",
    "\n",
    "    env.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf582ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cf582ac",
    "outputId": "10bf71ab-5147-4cd9-bc8d-c84f008e8522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATING: 5x5\n",
      "==================================================\n",
      "Double DQN model not found at: models/5x5/double_dqn_model.pth\n",
      "PPO model not found at: models/5x5/ppo_model.pth\n",
      "\n",
      "==================================================\n",
      "EVALUATING: 6x6\n",
      "==================================================\n",
      "Double DQN model not found at: models/6x6/double_dqn_model.pth\n",
      "Loading PPO model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PPO...\n",
      "  Episode 0: Reward=0.88, Steps=19, Success=True\n",
      "  Episode 20: Reward=0.93, Steps=11, Success=True\n",
      "  Episode 40: Reward=0.91, Steps=15, Success=True\n",
      "  Episode 60: Reward=0.84, Steps=26, Success=True\n",
      "  Episode 80: Reward=0.91, Steps=15, Success=True\n"
     ]
    }
   ],
   "source": [
    "# Run evaluations for trained neural network models\n",
    "# Based on the environments used in training notebook\n",
    "configs = [\n",
    "    '5x5',\n",
    "    '6x6',\n",
    "    # '16x16'\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for config_name in configs:\n",
    "    all_results[config_name] = run_evaluation(config_name, f'MiniGrid-Dynamic-Obstacles-{config_name}-v0')\n",
    "\n",
    "# Add summary metrics\n",
    "for config_name, results in all_results.items():\n",
    "    for alg_name, metrics in results.items():\n",
    "        if metrics:  # Only process if results exist\n",
    "            metrics[\"success_rate\"] = np.mean(metrics[\"successes\"])\n",
    "            metrics[\"avg_reward\"] = np.mean(metrics[\"rewards\"])\n",
    "            metrics[\"avg_steps\"] = np.mean(metrics[\"steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a6e0517",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0a6e0517",
    "outputId": "4f87911a-79a9-41c9-cb45-e23a7b53cf82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "Configuration   Algorithm          Success Rate Avg Reward   Avg Steps \n",
      "----------------------------------------------------------------------\n",
      "6x6             PPO                1.000        0.889        17.7      \n",
      "\n",
      "==================================================\n",
      "PERFORMANCE VIDEOS\n",
      "==================================================\n",
      "\n",
      "5x5 Results:\n",
      "\n",
      "6x6 Results:\n",
      "\n",
      "PPO - Success Rate: 1.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  width=\"400\"  height=\"300\">\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results summary and video display\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EVALUATION RESULTS SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"{'Configuration':<15} {'Algorithm':<18} {'Success Rate':<12} {'Avg Reward':<12} {'Avg Steps':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for config_name, results in all_results.items():\n",
    "    for alg_name, metrics in results.items():\n",
    "        success_rate = metrics[\"success_rate\"]\n",
    "        print(f\"{config_name:<15} {alg_name:<18} {success_rate:<12.3f} {metrics['avg_reward']:<12.3f} {metrics['avg_steps']:<10.1f}\")\n",
    "\n",
    "# Display videos\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"PERFORMANCE VIDEOS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "for config_name, results in all_results.items():\n",
    "    print(f\"\\n{config_name} Results:\")\n",
    "    for alg_name, metrics in results.items():\n",
    "        print(f\"\\n{alg_name} - Success Rate: {metrics['success_rate']:.3f}\")\n",
    "        display(Video(metrics[\"video\"], width=400, height=300, embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f0388de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_comparison(all_results, env_name):\n",
    "    \"\"\"Plot comparison between Double DQN and PPO for a configuration.\"\"\"\n",
    "    if env_name not in all_results:\n",
    "        print(f\"No results found for {env_name}\")\n",
    "        return\n",
    "    \n",
    "    results = all_results[env_name]\n",
    "    \n",
    "    # Check if both algorithms have results\n",
    "    if \"Double DQN\" not in results or \"PPO\" not in results:\n",
    "        print(f\"Missing algorithm results for {env_name}\")\n",
    "        available_algs = list(results.keys())\n",
    "        print(f\"Available algorithms: {available_algs}\")\n",
    "        return\n",
    "    \n",
    "    dqn_results = results[\"Double DQN\"]\n",
    "    ppo_results = results[\"PPO\"]\n",
    "\n",
    "    print(f\"\\n{env_name} Results:\")\n",
    "    print(f\"Double DQN – Success Rate: {np.mean(dqn_results['successes']):.3f}, \"\n",
    "          f\"Avg Reward: {np.mean(dqn_results['rewards']):.3f}, \"\n",
    "          f\"Avg Steps: {np.mean(dqn_results['steps']):.1f}\")\n",
    "\n",
    "    print(f\"PPO – Success Rate: {np.mean(ppo_results['successes']):.3f}, \"\n",
    "          f\"Avg Reward: {np.mean(ppo_results['rewards']):.3f}, \"\n",
    "          f\"Avg Steps: {np.mean(ppo_results['steps']):.1f}\")\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f\"{env_name} - Double DQN vs PPO\", fontsize=16)\n",
    "\n",
    "    # Histogram of rewards\n",
    "    axs[0].hist(dqn_results[\"rewards\"], bins=20, alpha=0.6, label=\"Double DQN\", color='blue')\n",
    "    axs[0].hist(ppo_results[\"rewards\"], bins=20, alpha=0.6, label=\"PPO\", color='orange')\n",
    "    axs[0].set_title(\"Total Rewards\")\n",
    "    axs[0].set_xlabel(\"Reward\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(alpha=0.3)\n",
    "\n",
    "    # Histogram of steps\n",
    "    axs[1].hist(dqn_results[\"steps\"], bins=20, alpha=0.6, label=\"Double DQN\", color='blue')\n",
    "    axs[1].hist(ppo_results[\"steps\"], bins=20, alpha=0.6, label=\"PPO\", color='orange')\n",
    "    axs[1].set_title(\"Episode Lengths\")\n",
    "    axs[1].set_xlabel(\"Steps\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(alpha=0.3)\n",
    "\n",
    "    # Success rate over episodes\n",
    "    dqn_sr = np.cumsum(dqn_results[\"successes\"]) / np.arange(1, len(dqn_results[\"successes\"]) + 1)\n",
    "    ppo_sr = np.cumsum(ppo_results[\"successes\"]) / np.arange(1, len(ppo_results[\"successes\"]) + 1)\n",
    "\n",
    "    axs[2].plot(dqn_sr, label=\"Double DQN\", linewidth=2, color='blue')\n",
    "    axs[2].plot(ppo_sr, label=\"PPO\", linewidth=2, color='orange')\n",
    "    axs[2].set_title(\"Cumulative Success Rate\")\n",
    "    axs[2].set_xlabel(\"Episode\")\n",
    "    axs[2].set_ylabel(\"Success Rate\")\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bc8109f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8bc8109f",
    "outputId": "c2d6771b-fa74-44cc-9409-ea735a95dee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "Missing algorithm results for 6x6\n",
      "Available algorithms: ['PPO']\n",
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETAILED PERFORMANCE ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Plot comparisons for each environment that has results\n",
    "for env_name in all_results.keys():\n",
    "    if all_results[env_name]:  # Only plot if there are results\n",
    "        plot_eval_comparison(all_results, env_name)\n",
    "\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
